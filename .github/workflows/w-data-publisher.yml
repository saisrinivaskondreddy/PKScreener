# """
#     The MIT License (MIT)

#     Copyright (c) 2023 pkjmesra

#     Permission is hereby granted, free of charge, to any person obtaining a copy
#     of this software and associated documentation files (the "Software"), to deal
#     in the Software without restriction, including without limitation the rights
#     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#     copies of the Software, and to permit persons to whom the Software is
#     furnished to do so, subject to the following conditions:

#     The above copyright notice and this permission notice shall be included in all
#     copies or substantial portions of the Software.

#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#     SOFTWARE.

# """
name: Data Publisher - Scalable Candle Data

# This workflow publishes candle data to the repository for consumption by scan workflows.
# It eliminates Telegram bot-to-bot communication by using GitHub as the data layer.
#
# Benefits:
# - No Telegram rate limits or file size limits
# - Parallel access from multiple scan workflows
# - 2-5 second data fetch latency (vs 30-60 seconds via Telegram)
# - Git-backed durability

on:
  schedule:
    # Run every 5 minutes during market hours (IST 9:15-15:30 = UTC 3:45-10:00)
    - cron: '*/5 3-10 * * 1-5'
    
  workflow_dispatch:
    inputs:
      cleanup:
        description: 'Clean up old snapshot directories (Y/N)'
        required: false
        default: 'N'
      keep_days:
        description: 'Number of days to keep for cleanup'
        required: false
        default: '7'

run-name: Data Publisher ${{ github.event.inputs.cleanup == 'Y' && '(with cleanup)' || '' }}

jobs:

  Check_Market_Hours:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
    steps:
      - name: Check if market hours
        id: check
        shell: python
        run: |
          import os
          from datetime import datetime
          import pytz
          
          ist = pytz.timezone('Asia/Kolkata')
          now = datetime.now(ist)
          
          # Market hours: 9:15 AM to 3:35 PM IST (with buffer)
          market_start = now.replace(hour=9, minute=10, second=0, microsecond=0)
          market_end = now.replace(hour=15, minute=35, second=0, microsecond=0)
          
          # Skip weekends
          is_weekday = now.weekday() < 5
          is_market_hours = market_start <= now <= market_end
          
          should_run = "true" if (is_weekday and is_market_hours) else "false"
          
          # For manual dispatch, always run
          if "${{ github.event_name }}" == "workflow_dispatch":
              should_run = "true"
          
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"should_run={should_run}\n")
          
          print(f"Current IST time: {now}")
          print(f"Should run: {should_run}")

  Publish_Data:
    needs: Check_Market_Hours
    if: needs.Check_Market_Hours.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: actions-data-download
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install requests pandas pytz

      - name: Configure environment
        env:
          KTOKEN: ${{ secrets.KTOKEN }}
          KUSER: ${{ secrets.KUSER }}
          KPWD: ${{ secrets.KPWD }}
          KTOTP: ${{ secrets.KTOTP }}
        run: |
          cat > .env.dev << EOF
          KTOKEN=$KTOKEN
          KUSER=$KUSER
          KPWD=$KPWD
          KTOTP=$KTOTP
          EOF

      - name: Collect and publish candle data
        id: publish
        run: |
          python << 'EOF'
          import gzip
          import json
          import os
          import pickle
          from datetime import datetime
          from urllib.request import urlopen, Request
          
          # Create data directory
          os.makedirs("results/Data", exist_ok=True)
          
          # Try to fetch existing ticks data from live system or create sample
          data = {}
          metadata = {
              "last_update": datetime.utcnow().isoformat() + "Z",
              "version": "2.0.0",
              "publisher": "w-data-publisher.yml",
          }
          
          # Check if we have local candle data (from pktickbot)
          ticks_paths = [
              os.path.expanduser("~/pkscreener/ticks.json"),
              "ticks.json",
              "results/Data/ticks.json"
          ]
          
          for ticks_path in ticks_paths:
              if os.path.exists(ticks_path):
                  try:
                      with open(ticks_path, 'r') as f:
                          data = json.load(f)
                      print(f"Loaded {len(data)} instruments from {ticks_path}")
                      break
                  except Exception as e:
                      print(f"Error loading {ticks_path}: {e}")
          
          # If no local data, try to fetch from existing GitHub data
          if not data:
              try:
                  url = "https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/results/Data/ticks.json"
                  req = Request(url, headers={"User-Agent": "PKScreener/2.0"})
                  with urlopen(req, timeout=30) as resp:
                      data = json.loads(resp.read().decode())
                  print(f"Fetched {len(data)} instruments from GitHub")
              except Exception as e:
                  print(f"Could not fetch from GitHub: {e}")
          
          # Save data
          if data:
              # Save compressed candles
              with gzip.open("results/Data/candles_latest.json.gz", 'wt', encoding='utf-8') as f:
                  json.dump(data, f)
              
              # Save uncompressed ticks.json
              with open("results/Data/ticks.json", 'w') as f:
                  json.dump(data, f)
              
              metadata["instrument_count"] = len(data)
              metadata["health"] = {"status": "healthy"}
              print(f"Published data for {len(data)} instruments")
          else:
              metadata["instrument_count"] = 0
              metadata["health"] = {"status": "no_data"}
              print("No data to publish")
          
          # Save metadata
          with open("results/Data/metadata.json", 'w') as f:
              json.dump(metadata, f, indent=2)
          
          print("Data publishing complete")
          EOF

      - name: Cleanup old snapshots
        if: ${{ github.event.inputs.cleanup == 'Y' }}
        run: |
          python << 'EOF'
          import os
          import shutil
          from datetime import datetime, timedelta
          
          keep_days = int("${{ github.event.inputs.keep_days }}" or "7")
          cutoff = (datetime.now() - timedelta(days=keep_days)).strftime("%Y-%m-%d")
          
          candles_dir = "results/Data/candles"
          if os.path.exists(candles_dir):
              for dirname in os.listdir(candles_dir):
                  if len(dirname) == 10 and dirname < cutoff:
                      dir_path = os.path.join(candles_dir, dirname)
                      if os.path.isdir(dir_path):
                          shutil.rmtree(dir_path)
                          print(f"Cleaned up: {dirname}")
          EOF

      - name: Commit and push data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "actions@github.com"
          
          git add results/Data/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Data update $(date -u +%Y-%m-%dT%H:%M:%SZ)"
            git push
            echo "Data published successfully"
          fi

  Notify_Status:
    needs: [Check_Market_Hours, Publish_Data]
    if: always() && needs.Check_Market_Hours.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - name: Send status to Telegram (optional)
        if: failure()
        env:
          TOKEN: ${{ secrets.TOKEN_DEV }}
          CHAT_ID: ${{ secrets.CHAT_IDADMIN_DEV }}
        run: |
          if [ -n "$TOKEN" ] && [ -n "$CHAT_ID" ]; then
            curl -s -X POST "https://api.telegram.org/bot$TOKEN/sendMessage" \
              -d chat_id="$CHAT_ID" \
              -d text="⚠️ Data Publisher workflow failed at $(date -u +%H:%M:%S) UTC" \
              -d parse_mode="HTML" || true
          else
            echo "Telegram notification skipped - TOKEN_DEV or CHAT_ID not configured"
          fi
